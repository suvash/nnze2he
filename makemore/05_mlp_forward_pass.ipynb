{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c81875e8-a315-4291-b887-b4124aee8c6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ced35ac6-8fca-46f1-a130-9b97481678ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c0f3450e-a739-4104-ae99-b1932c4565f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32033,\n",
       " ['emma', 'olivia', 'ava', 'isabella', 'sophia', 'charlotte', 'mia', 'amelia'])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words = open('names.txt').read().splitlines()\n",
    "len(words), words[:8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "30aed53a-f437-4d8c-96aa-e5cc1afa6bc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's only have one special token, and let's have it at index 0, offset others by 1\n",
    "chars = sorted(list(set(''.join(words))))\n",
    "stoi = {s:i+1 for i,s in enumerate(chars)}\n",
    "stoi['.'] = 0\n",
    "itos = {i:s for s,i in stoi.items()}\n",
    "num_classes = len(stoi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "387595f8-942c-4093-9acd-469dc7b74301",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "emma\n",
      "... --------> e\n",
      "..e --------> m\n",
      ".em --------> m\n",
      "emm --------> a\n",
      "mma --------> .\n",
      "olivia\n",
      "... --------> o\n",
      "..o --------> l\n",
      ".ol --------> i\n",
      "oli --------> v\n",
      "liv --------> i\n",
      "ivi --------> a\n",
      "via --------> .\n",
      "ava\n",
      "... --------> a\n",
      "..a --------> v\n",
      ".av --------> a\n",
      "ava --------> .\n",
      "isabella\n",
      "... --------> i\n",
      "..i --------> s\n",
      ".is --------> a\n",
      "isa --------> b\n",
      "sab --------> e\n",
      "abe --------> l\n",
      "bel --------> l\n",
      "ell --------> a\n",
      "lla --------> .\n",
      "sophia\n",
      "... --------> s\n",
      "..s --------> o\n",
      ".so --------> p\n",
      "sop --------> h\n",
      "oph --------> i\n",
      "phi --------> a\n",
      "hia --------> .\n"
     ]
    }
   ],
   "source": [
    "# test build the dataset\n",
    "block_size = 3 # How many characters do we take to predict the next one : 3 chars to predict the 4th\n",
    "for w in words[:5]:\n",
    "    print(w)\n",
    "    context = [0] * block_size\n",
    "    for ch in w + '.':\n",
    "        ix = stoi[ch]\n",
    "        print(''.join(itos[i] for i in context), '-------->', itos[ix])\n",
    "        context = context[1:] + [ix] # crop and append moving window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7d9ba170-262e-44ca-9683-d9a9a96adb16",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([32, 3]), torch.int64, torch.Size([32]), torch.int64)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# build the dataset (only for N words right now)\n",
    "\n",
    "block_size = 3 # How many characters do we take to predict the next one : 3 chars to predict the 4th\n",
    "X, Y, = [], [] # X, input | Y, labels\n",
    "\n",
    "for w in words[:5]:\n",
    "    context = [0] * block_size\n",
    "    for ch in w + '.':\n",
    "        ix = stoi[ch]\n",
    "        X.append(context)\n",
    "        Y.append(ix)\n",
    "        context = context[1:] + [ix] # crop and append moving window\n",
    "\n",
    "X = torch.tensor(X)\n",
    "Y = torch.tensor(Y)\n",
    "\n",
    "X.shape, X.dtype, Y.shape, Y.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f21fe297-8d27-4f1c-889d-4b61ebea6e39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# similar to paper cramming 17000 words into 30 dim space\n",
    "# we have 5 words so lets cram it into a 2 dimensional space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0bb364f8-5cc6-4a80-b947-539aee192936",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([27, 2]), torch.float32)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "C = torch.randn(27, 2) # each of the 27 chars will have a 2 dimensional embedding\n",
    "C.shape, C.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6a02a31e-332a-4587-9e9d-2d0b132ab0ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 2.0808, -0.0085])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# to access the embeddings for the 5th character\n",
    "C[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a679bd70-77ea-4472-b84b-c097beeec8fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 2.0808, -0.0085])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the other way to do it is to use one hot encoded vectors to lookup via matrix multplication\n",
    "# they're equivalent interpretations\n",
    "F.one_hot(torch.tensor(5), num_classes=27).float() @ C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c64f83e5-1e00-4cfc-840e-7c9fd2308f14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([27, 2]), torch.Size([32, 3]))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "C.shape, X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f0cc444a-8f7a-4130-827c-c90d14639bf7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([2]), torch.Size([3, 2]))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "C[1].shape, C[[1,2,3]].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "25a4e2b9-580c-41b9-89c9-56d4ca91e761",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 3, 2])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "C[X].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2cfba109-8c22-4039-a06e-6d1b71a15a68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[13,2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "64ad20ed-fc28-42bc-94c3-e2fe91583ab1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([-1.5018, -0.6028]), tensor([-1.5018, -0.6028]))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "C[X][13,2], C[X[13,2]] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "65d00668-a3dd-4ece-a279-ba748d451c27",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 3, 2])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# this pytorch indexing is still a bit confusing for me\n",
    "# each value in X(index of the char) is being indexed into the C tensor which has a 2 dim embedding for each char possible\n",
    "# hence this indexing pulls out the embedding for each char in the X tensor, given 32 rows, 3 chars each with 2 dims\n",
    "# think a bit more and it makes sense\n",
    "emb = C[X]\n",
    "# what's useful though is thinking of the embedding matrix needed\n",
    "# as seen from above 32 samples with 3 characters each with 2 dim embedding\n",
    "emb.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "92eccc59-86cd-4925-b0da-064a6d6ef03d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([6, 100]), torch.Size([100]))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W1 = torch.randn(3*2, 100) # 2 dim embedding, 3 of them, say 100 neurons\n",
    "b1 = torch.randn(100)\n",
    "W1.shape, b1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d7fedd15-0983-44e7-9d64-ea753a95a50f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# note that the shapes for embedding and W1 are not multipliable\n",
    "# has to be reshaped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8066d463-f963-4476-ab9a-2c8c21c60393",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 2])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# let try concatenating first\n",
    "emb[:, 0, :].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e0083cdb-e85c-4ebd-ba1a-ab39d4cdf69a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 6])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# using torch.cat and ugly stacking\n",
    "torch.cat([emb[:, 0, :], emb[:, 1, :], emb[:, 1, :]], dim=1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f4302270-a6fa-4bf7-98bd-16bda00744b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 6])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# using torch.unbind (on dim 1) and then cat-ing it\n",
    "torch.cat(torch.unbind(emb, dim=1), dim=1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2a943283-3ac7-4251-9a79-af5756abd26e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# short intro to view and storage on a tensor\n",
    "# tensor's internal storage is always a 1 dim tensor\n",
    "# view is how you can change the way you arrange it\n",
    "# storage offset, strides, shapes\n",
    "# good reading here\n",
    "# http://blog.ezyang.com/2019/05/pytorch-internals/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5b05d5c5-9b6a-4a2a-a303-37a8d0f689dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 6])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# view is pretty efficient\n",
    "emb.view(32, 6).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9e57bb06-0b88-4707-879a-224ea02b9ef0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 100])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Finally we can go back to multiplication of weights and biases\n",
    "# -1 requires view to infer the shape\n",
    "# lets get the activations\n",
    "h = torch.tanh(emb.view(-1, W1.shape[0]) @ W1 + b1)\n",
    "h.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "15974544-faa6-414e-9ec6-6de32c5da74d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CHECK YO DTYPES\n",
    "# CHECK YO SHAPES\n",
    "# CHECK YO BROADCASTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7b30c282-09e9-42a3-bf16-d5d69c796ab3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([100, 27]), torch.Size([27]))"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# final layer - input 100 from hidden layer, output 27 possible chars\n",
    "W2 = torch.rand(100, 27)\n",
    "b2 = torch.rand(27)\n",
    "\n",
    "W2.shape, b2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "dc32b3af-9f52-4453-b979-b66d8e8c8b38",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 27])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Final logits you\n",
    "logits = h @ W2 + b2\n",
    "logits.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e3ebd7ce-573b-463a-b27e-c1635130b965",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets get the counts\n",
    "counts = logits.exp()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6135a300-ac7a-491b-adaf-bc668f448a2d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 27])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# finally the softmax\n",
    "probs = counts / counts.sum(dim=1, keepdims=True)\n",
    "probs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5af94ad5-5935-4db0-9555-80e50f86fffd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check that rows sum to 1\n",
    "probs.sum(dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "05ec8bcf-8a2d-472a-b5a9-a7dc94c5728d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
       "        18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now that we have probs, time to get the loss\n",
    "# for each Y (which is an int)\n",
    "# need to pick out the corresponding prob for it from each corresponding row\n",
    "torch.arange(32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e33a6492-88f3-469a-866e-a176e1fceebd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.2748e-03, 2.4018e-03, 1.2570e-04, 1.5168e-02, 8.5282e-03, 5.6672e-05,\n",
       "        3.2609e-01, 6.7816e-03, 1.3303e-02, 1.2102e-02, 1.9635e-03, 2.7434e-02,\n",
       "        7.8319e-04, 9.5160e-02, 3.9812e-05, 3.8317e-02, 1.0551e-02, 2.5108e-02,\n",
       "        3.5615e-03, 2.6272e-01, 2.7493e-03, 5.1367e-03, 2.6550e-06, 9.3671e-03,\n",
       "        9.8317e-03, 1.0469e-02, 5.0911e-05, 5.3057e-03, 8.0725e-02, 4.6308e-03,\n",
       "        9.1132e-03, 2.2840e-02])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# to pick the prob for each Y for each row, using the arange as the row and Y as the col lookup\n",
    "probs[torch.arange(len(Y)), Y]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e77292ab-7c47-4411-810c-930fdfb5ba3e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(5.3921)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# now for the loss\n",
    "# get the log of probs(likelihood), then the average, and obv negative\n",
    "loss = -probs[torch.arange(len(Y)), Y].log().mean()\n",
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "cc93ef18-bcb0-4fc6-9508-250090cbae84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cleanup on next nb"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
