{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "68d000a8-ed81-4108-9f42-c4574ee47349",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Post programming discussions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "206a851a-eeff-4df0-83c1-485b08e276d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# python gpt.py was able to get pretty low losses\n",
    "# and text generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2beeb04a-02f2-4790-af49-891d266562b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# step 4500: train loss 1.0845, val loss 1.4752\n",
    "\n",
    "# Thy wrong and fruitting men!\n",
    "\n",
    "# BALTHASAR:\n",
    "# Why, then might I love this by perfoceiving little\n",
    "# Where strengthen'd such royalty, like humble frightion,\n",
    "# Were nothing reverence cliped pursuaged away!\n",
    "# Nury, and is he lords run their leap,\n",
    "# The white life is onators, the tempest along;\n",
    "# I neglect, being no rare ipsued, and true confermity\n",
    "# Their power-watch.\n",
    "\n",
    "# BRUTUS:\n",
    "# I was our words with a name bare?\n",
    "\n",
    "# Servant:\n",
    "# You will walk upon the cleasure that gatlemans clap\n",
    "# mock ately! cry that have; now your penition,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0d03b1ea-fa6f-4a54-9236-2887eab2f2f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pretty decent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "30b9ece9-f6c7-4211-8097-7d28e596d00b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We implemented Decoder only arch\n",
    "# no cross attention and no encoder\n",
    "\n",
    "# The reason it's decoder only is that we are only doing generation\n",
    "# no conditioned on any other text\n",
    "\n",
    "# What makes it a decoder is that we are using the triangular mask (mask out future tokens)\n",
    "# Reason original paper has encoder decoder arch. is that it's a machine translation paper\n",
    "\n",
    "# Decoder has to generate conditioned on the Encoder tokens\n",
    "# In encoder there's no triangular mask\n",
    "# Once it's encoded, the values come out of the top\n",
    "# In the decoder there's additional connection to the outputs of the encoder\n",
    "# which si brought in through cross attention\n",
    "\n",
    "# in decoder, queries are still generated\n",
    "# but keys and values come from the encoder side\n",
    "# the decoding happens not only on self attention of past tokens\n",
    "# but also from the cross attention of having seen the encoder keys and values"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
