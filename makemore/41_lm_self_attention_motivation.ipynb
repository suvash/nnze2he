{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f0457004-e184-42d2-94e9-b576ebe57a77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Self Attention block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "719634c9-51c7-4b0f-8c0e-d771f7a352e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mathematical trick in self attention\n",
    "# at the heart of an efficient implementation of self attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f2eb2e79-bef2-4944-b2ed-aa4ca2fdf74a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1d6bfc7f-67fb-4c3d-b4bb-c8ecc41eb6be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 8, 2])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(1337)\n",
    "B, T, C = 4, 8, 2 # Batch, Time, Channels : Time component being the given x tokens predict next token which moves over time\n",
    "x = torch.randn(B, T, C)\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "017fc6cd-f827-4431-9032-ce4afdb291ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we'd like these 8 tokens in the time dimension to talk to each other\n",
    "# in particular, we have a specific config in mind\n",
    "# token at Nth place should only talk to tokens < Nth place, cannot talk to future tokens since they're supposed to be predicted\n",
    "# 5th token should only talk to 4th, 3rd, 2nd and 1st\n",
    "# information only flows from previous context to the current one, cannot get information from future context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fc1c34bc-9c5d-4c89-8d47-bbdbc4577e36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the simplest way to communicate is to average all tokens of the preceeding elements\n",
    "# the average could be the feature vector of me in the context of my history\n",
    "# just sum or average is extremely weak form of interaction - extremely lossy - but okay for now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "20954f49-bd50-4b7a-b4d1-7980cee7209e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for every single batch element independently\n",
    "# for every Tth token, we'd like to calculate the average of all the vectors in all the previous tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "61e66a9d-b2a2-4c93-8146-b330cbdd0598",
   "metadata": {},
   "outputs": [],
   "source": [
    "# version 1 : nested for loop select previous and mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "871b17f1-01dd-442c-8ef6-9a3dfa3458db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we want x[b, t] = mean_{i<=t} x[b, i]\n",
    "xbow = torch.zeros(B, T, C) # bow = bag of words : term used when averaging up words\n",
    "for b in range(B):\n",
    "    for t in range(T):\n",
    "        xprev = x[b, :t+1] # (t, C)\n",
    "        xbow[b, t] = torch.mean(xprev, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b36609fb-443d-45f9-a83a-d3c6707fc6c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 8, 2])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xbow.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f0838cb3-d99b-4491-9724-c31fe41a9f2d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.1808, -0.0700],\n",
       "        [-0.3596, -0.9152],\n",
       "        [ 0.6258,  0.0255],\n",
       "        [ 0.9545,  0.0643],\n",
       "        [ 0.3612,  1.1679],\n",
       "        [-1.3499, -0.5102],\n",
       "        [ 0.2360, -0.2398],\n",
       "        [-0.9211,  1.5433]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a1f3c1b0-2ddb-4a4e-b7c9-f378dcacb07c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.1808, -0.0700],\n",
       "        [-0.0894, -0.4926],\n",
       "        [ 0.1490, -0.3199],\n",
       "        [ 0.3504, -0.2238],\n",
       "        [ 0.3525,  0.0545],\n",
       "        [ 0.0688, -0.0396],\n",
       "        [ 0.0927, -0.0682],\n",
       "        [-0.0341,  0.1332]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xbow[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f98eb3c6-b734-4599-802a-1af2c6827c12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Notice how the averages are above, at any given row they're the averages of the all the rows above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b3af777c-060e-4af7-8265-8c086127ef9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([True, True])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.mean(x[0, :5], dim=0) == xbow[0, 4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0d6e370a-e024-4062-a830-87c27e94dde6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# version 2 : lower triangular normalised over rows matrix multiply"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5d4213c7-f85f-4f51-bd99-5ceaf2a19dba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can very very efficient about this using matrix multiplication\n",
    "# lets look at a toy example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a2f4f82d-8402-48ed-adf8-184d9bcf468f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a=\n",
      "tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.]])\n",
      "---\n",
      "b=\n",
      "tensor([[2., 7.],\n",
      "        [6., 4.],\n",
      "        [6., 5.]])\n",
      "---\n",
      "c=\n",
      "tensor([[14., 16.],\n",
      "        [14., 16.],\n",
      "        [14., 16.]])\n",
      "---\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(42)\n",
    "a = torch.ones(3, 3)\n",
    "b = torch.randint(0, 10, (3, 2)).float()\n",
    "c = a @ b\n",
    "print(f'a=\\n{a}\\n---')\n",
    "print(f'b=\\n{b}\\n---')\n",
    "print(f'c=\\n{c}\\n---')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1dcb641b-1c72-4bc0-84e2-372e4e03b357",
   "metadata": {},
   "outputs": [],
   "source": [
    "# what i was thinking (about masking upper triangle of a matrix\n",
    "# torch has a function called tril that returns the lower triangular matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "15f447b2-2832-4d74-b199-df648374d787",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 0., 0.],\n",
       "        [1., 1., 0.],\n",
       "        [1., 1., 1.]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tril(torch.ones(3, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e8da72df-46e1-4dd0-842e-6a7b4d78a3cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets check what happens when we do that"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "eafa496a-2561-4b83-8472-f0d14055fcec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a=\n",
      "tensor([[1., 0., 0.],\n",
      "        [1., 1., 0.],\n",
      "        [1., 1., 1.]])\n",
      "---\n",
      "b=\n",
      "tensor([[2., 7.],\n",
      "        [6., 4.],\n",
      "        [6., 5.]])\n",
      "---\n",
      "c=\n",
      "tensor([[ 2.,  7.],\n",
      "        [ 8., 11.],\n",
      "        [14., 16.]])\n",
      "---\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(42)\n",
    "a = torch.tril(torch.ones(3, 3))\n",
    "b = torch.randint(0, 10, (3, 2)).float()\n",
    "c = a @ b\n",
    "print(f'a=\\n{a}\\n---')\n",
    "print(f'b=\\n{b}\\n---')\n",
    "print(f'c=\\n{c}\\n---')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8e1d5d5f-5904-4162-aff0-f6ed1d2a4b8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# notice how we are doing sums of the previous rows*\n",
    "# current we are doing sums, we could do an average as well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9efc18fd-6d01-4d57-9645-decd546ad1cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if we normalize the elements of the lower triangular matrix to sum to 1.0, then the matrix product will be an average of previous rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0a863f3d-c42c-4206-bd79-186e313ea4b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 0., 0.],\n",
       "        [1., 1., 0.],\n",
       "        [1., 1., 1.]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tril(torch.ones(3, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "cc4838fa-4a35-4f26-96f6-7e363a19b347",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.],\n",
       "        [2.],\n",
       "        [3.]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.sum(torch.tril(torch.ones(3, 3)), 1, keepdim=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e7e36c0d-45c0-4e1c-b08d-6e98c2ba1db6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.0000, 0.0000, 0.0000],\n",
       "        [0.5000, 0.5000, 0.0000],\n",
       "        [0.3333, 0.3333, 0.3333]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.tril(torch.ones(3, 3))\n",
    "a = a / a.sum(dim=1, keepdim=True)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9d3dde29-b41a-40b6-865c-4762a291baa1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a=\n",
      "tensor([[1.0000, 0.0000, 0.0000],\n",
      "        [0.5000, 0.5000, 0.0000],\n",
      "        [0.3333, 0.3333, 0.3333]])\n",
      "---\n",
      "b=\n",
      "tensor([[2., 7.],\n",
      "        [6., 4.],\n",
      "        [6., 5.]])\n",
      "---\n",
      "c=\n",
      "tensor([[2.0000, 7.0000],\n",
      "        [4.0000, 5.5000],\n",
      "        [4.6667, 5.3333]])\n",
      "---\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(42)\n",
    "a = torch.tril(torch.ones(3, 3))\n",
    "a = a / a.sum(dim=1, keepdim=True)\n",
    "b = torch.randint(0, 10, (3, 2)).float()\n",
    "c = a @ b\n",
    "print(f'a=\\n{a}\\n---')\n",
    "print(f'b=\\n{b}\\n---')\n",
    "print(f'c=\\n{c}\\n---')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1c3a1715-e3c9-4076-aaff-d71215d1cc0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# by manpulating the elements of multiplying matrix we can compute the averages in an incremental fashion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "49d339ac-cce2-42ff-bc7c-2af79244b615",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets take the same nested for loop example above and vectorize it to make it more efficient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c2f2e0fc-0ddf-4216-ad99-eb7b871c5433",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.5000, 0.5000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.3333, 0.3333, 0.3333, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.2500, 0.2500, 0.2500, 0.2500, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.2000, 0.2000, 0.2000, 0.2000, 0.2000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.1667, 0.1667, 0.1667, 0.1667, 0.1667, 0.1667, 0.0000, 0.0000],\n",
       "        [0.1429, 0.1429, 0.1429, 0.1429, 0.1429, 0.1429, 0.1429, 0.0000],\n",
       "        [0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250]])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wei = torch.tril(torch.ones(T, T))\n",
    "wei = wei / wei.sum(dim=1, keepdim=True)\n",
    "wei"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "cebae4f4-3f08-464e-a225-c2aa45232738",
   "metadata": {},
   "outputs": [],
   "source": [
    "xbow2 = wei @ x # (T, T) @ (B, T, C) => (B, T, T) @ (B, T, C) => batched matrix mult => (B, T, C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e2448a4b-c20f-414d-a60b-bd319366aba5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.allclose(xbow, xbow2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "84fa2930-0df8-4d6a-a0ec-dd6acb2de505",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 0.1808, -0.0700],\n",
       "         [-0.0894, -0.4926],\n",
       "         [ 0.1490, -0.3199],\n",
       "         [ 0.3504, -0.2238],\n",
       "         [ 0.3525,  0.0545],\n",
       "         [ 0.0688, -0.0396],\n",
       "         [ 0.0927, -0.0682],\n",
       "         [-0.0341,  0.1332]]),\n",
       " tensor([[ 0.1808, -0.0700],\n",
       "         [-0.0894, -0.4926],\n",
       "         [ 0.1490, -0.3199],\n",
       "         [ 0.3504, -0.2238],\n",
       "         [ 0.3525,  0.0545],\n",
       "         [ 0.0688, -0.0396],\n",
       "         [ 0.0927, -0.0682],\n",
       "         [-0.0341,  0.1332]]))"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xbow[0], xbow2[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "cf3b125c-c22a-4608-97d2-5d0ea208c86d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# version 3 : using softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "64de3dfb-c1e3-417a-bddf-cf8fbae3169a",
   "metadata": {},
   "outputs": [],
   "source": [
    "tril = torch.tril(torch.ones(T, T))\n",
    "wei  = torch.zeros(T, T) # torch.ones(T, T) : doesn't matter as long as all elments equal since they'll get softmaxed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ddf4f4af-4aeb-45b5-9bb0-905fc62f8d36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., -inf, -inf, -inf, -inf, -inf, -inf, -inf],\n",
       "        [0., 0., -inf, -inf, -inf, -inf, -inf, -inf],\n",
       "        [0., 0., 0., -inf, -inf, -inf, -inf, -inf],\n",
       "        [0., 0., 0., 0., -inf, -inf, -inf, -inf],\n",
       "        [0., 0., 0., 0., 0., -inf, -inf, -inf],\n",
       "        [0., 0., 0., 0., 0., 0., -inf, -inf],\n",
       "        [0., 0., 0., 0., 0., 0., 0., -inf],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wei = wei.masked_fill(tril == 0, float('-inf'))\n",
    "wei"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "85370002-49eb-4f7a-8454-672b10e5fc67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# interesting thing with softmax is that, it effectively drops out the weights with -inf\n",
    "# and soft-maxes out the rest of the elements,\n",
    "# since the lower triangular is all equal, 0 in this case, could be any other numbers I think\n",
    "# they get soft-maxed out to equal normalised weights that sum up to 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "548f6a08-1f04-4e76-8934-f4c28343ac65",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.5000, 0.5000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.3333, 0.3333, 0.3333, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.2500, 0.2500, 0.2500, 0.2500, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.2000, 0.2000, 0.2000, 0.2000, 0.2000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.1667, 0.1667, 0.1667, 0.1667, 0.1667, 0.1667, 0.0000, 0.0000],\n",
       "        [0.1429, 0.1429, 0.1429, 0.1429, 0.1429, 0.1429, 0.1429, 0.0000],\n",
       "        [0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250]])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wei = F.softmax(wei, dim=1)\n",
    "wei"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "cd384c59-67cb-446e-9ba0-33afb221bae3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xbow3 = wei @ x\n",
    "torch.allclose(xbow3, xbow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "fc5b2137-1947-446c-86ad-87a31c719ee8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# in softmax we exponentiate every element, and the divide by their sum\n",
    "# exp(0) = 1, exp(-inf) = 0, then we normalise the sums"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "5f6760db-2bc8-44d9-a98b-b29586b86c87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The reason softmax is more interesting and it will be used later\n",
    "# the weights begin with zero, think of it as an affinity\n",
    "# how much of token from the past do we want to aggregate for the future\n",
    "# tokens from future cannot participate for the aggregation\n",
    "# the weights are going to be data dependent and learnable even if we start out at zero\n",
    "#\n",
    "# token will start interacting, find other tokens more or less interesting\n",
    "# depending on the values of the weights, the interest will be proportional, let's call that affinities\n",
    "# with a normalise and matrix mult of the affinities we will find the resulting interest values\n",
    "# that's the preview for self attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "bc0e62c1-5d20-402f-9414-a35349704cb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Long story short\n",
    "# You can do weighted aggeration of past elements\n",
    "# by using matrix multiplication\n",
    "# of a lower triangular fashion\n",
    "# the elements of which are telling you how much of each elements fused/contributes to an individual position"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
